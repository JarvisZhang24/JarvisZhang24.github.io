---
layout: home
description: Yichen Zhang — M.S. in Computer Engineering at NYU. Research in Vision-Language / Multimodal Learning, Embodied AI, and Robotics.
---

<div class="profile-section">
  <img class="profile-photo" src="{{ '/assets/profile.png' | relative_url }}" alt="Yichen Zhang">
  <div class="profile-info">
    <h1>Yichen Zhang</h1>
    <p class="affiliation">
      M.S. in Computer Engineering, New York University<br>
      Vision-Language Models · Multimodal Learning · Embodied AI · Robotics
    </p>
    <div class="profile-links">
      <a href="https://github.com/JarvisZhang24">GitHub</a>
      <a href="mailto:yz10759@nyu.edu">Email</a>
      <a href="{{ '/assets/Yichen_Zhang_Resume_Phd.pdf' | relative_url }}">CV</a>
    </div>
  </div>
</div>

<p class="bio-text">
I am a Master&rsquo;s student in Computer Engineering at New York University. My research focuses on vision-language models, multimodal learning, and embodied AI (VLA). I am broadly interested in building systems that bridge visual perception and language understanding for real-world applications.
</p>

<p class="bio-text">
Previously, I completed my B.S. in Communication Engineering at Beijing Jiaotong University and B.S. in Finance at Beijing Normal University, Zhuhai. I have worked on projects spanning schema-constrained generation with VLMs, efficient reasoning models, genomic variant analysis with foundation models, and optimal control of biological systems.
</p>

---

<h2 class="section-heading">Research Interests</h2>

<ul class="research-list">
  <li><strong>Vision-Language Models</strong> &mdash; Fine-tuning and adapting VLMs for structured generation, schema-constrained outputs, and multimodal understanding.</li>
  <li><strong>Efficient Reasoning</strong> &mdash; Analyzing compute-accuracy trade-offs in recursive and adaptive reasoning architectures.</li>
  <li><strong>AI for Science</strong> &mdash; Applying genomic foundation models to zero-shot variant pathogenicity prediction and biological sequence analysis.</li>
  <li><strong>Embodied AI &amp; Robotics</strong> &mdash; Exploring vision-language-action models for grounded decision-making in physical environments.</li>
</ul>

---

<h2 class="section-heading">Recent Updates</h2>

<table class="news-table">
  <tr><td class="news-date">2025</td><td>Released <a href="https://github.com/JarvisZhang24/llm-fine-tune-jarvis">weights &amp; demo</a> for schema-constrained food extraction with fine-tuned SmolVLM2-500M.</td></tr>
  <tr><td class="news-date">2025</td><td>Published efficiency analysis of Tiny Recursive Models on Sudoku-Extreme, characterizing accuracy&ndash;throughput trade-offs.</td></tr>
  <tr><td class="news-date">2025</td><td>Released <a href="https://github.com/JarvisZhang24/GeneLM-Evo2">GeneLM-Evo2</a>: zero-shot genomic variant pathogenicity scoring with Evo2 7B.</td></tr>
</table>
